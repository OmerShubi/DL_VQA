defaults:
  - hydra/job_logging: disabled
  - hydra/output_subdir: null
  - hydra/sweeper: ax


main:
  experiment_name_prefix: my_exp
  seed: 1
  num_workers: 8 #todo increase?
  use_full: False
  start_from_pretrained_model: False # If True make sure not using AX!!! and make sure model actually exists!
  full:
    paths:
      pretrained_model_path: './model.pth'
#      base_path: '/datashare'
      base_path: './zip'
      logs: 'logs/'
      vocab_path: './vocab.json'
    train_paths:
      vqaDataset: './vqaDataset_train.pkl'
      questions: 'v2_OpenEnded_mscoco_train2014_questions.json'
      answers: 'v2_mscoco_train2014_annotations.json'
      imgs: 'train2014'
      processed_imgs: './processed_train_images.h5'
    val_paths:
      vqaDataset: './vqaDataset_val.pkl'
      questions: 'v2_OpenEnded_mscoco_val2014_questions.json'
      answers: 'v2_mscoco_val2014_annotations.json'
      imgs: 'val2014'
      processed_imgs: './processed_val_images.h5'
  small:
    paths:
      pretrained_model_path: './model_small.pth'
      base_path: './small_data'
      logs: 'logs/'
      vocab_path: './vocab_small.json'
    train_paths:
      vqaDataset: './vqaDataset_train_small.pkl'
      questions: 'v2_OpenEnded_mscoco_train2014_questions.json'
      answers: 'v2_mscoco_train2014_annotations.json'
      imgs: 'train2014'
      processed_imgs: './processed_train_images_small.h5'
    val_paths:
      vqaDataset: './vqaDataset_val_small.pkl'
      questions: 'v2_OpenEnded_mscoco_val2014_questions.json'
      answers: 'v2_mscoco_val2014_annotations.json'
      imgs: 'val2014'
      processed_imgs: './processed_val_images_small.h5'
train:
  text:
    question_features: 1024
    embedding_features: 300
    dropout: 0.3
    num_lstm_layers: 1 # TODO change code if True!!
    bidirectional: True # False # OVERRIDEN
  image:
#    image_features: 64 # Todo not in use
    kernel_size: 3 # 5  # OVERRIDEN
    dropout: 0.3
    # num_channels OVERRIDEN
#    num_channels: [3, 6, 16, 32, 64] # last entry should match image_features
    num_channels: [3, 64, 128, 256] # last entry should match image_features
    stride: 1
  attention:
    hidden_dim: 1024 # 512 # OVERRIDEN
    glimpses: 2
    do_option: "|" # Options "*" / "+" / "|"
    dropout: 0.3
  classifier:
    hidden_dim: 1024
    dropout: 0.3

  max_answers: 3000
  image_size: 224 # scale shorter end of image to this size and centre crop
  central_fraction: 0.875  # only take this much of the centre when scaling and centre cropping

  n_epochs_stop: 6
  num_epochs: 80
  batch_size: 128
  save_model: True
  lr: # TODO what are reasonable values?
    lr_value: 1e-3
    lr_decay: 15
    lr_gamma: 0.1
    lr_step_size: 3
hydra:
  output_subdir: null
  run:
    dir: logs/hydra
  sweeper: # TODO update
    # The following part of config is used to setup the Hydra Ax plugin and is optional
    ax_config:
      # max_trials is application-specific. Tune it for your use case
      max_trials: 20

      experiment:
        # Default to minimize, set to false to maximize
        minimize: False

      early_stop:
        # Number of epochs without a significant improvement from
        # the currently known best parameters
        # An Epoch is defined as a batch of trials executed in parallel
        max_epochs_without_improvement: 20

      params:
        train.attention.hidden_dim:
          type: choice
          values: [ 512, 1024 ]
          is_ordered: True
          value_type: int
        train.text.bidirectional:
          type: choice
          values: [ False, True ]
          value_type: bool
        train.image.kernel_size:
          type: choice
          values: [ 3, 5 ]
          is_ordered: True
          value_type: int
        train.image.num_channels:
          type: choice
          values: [
            "[3, 64, 128, 256]",
            "[3, 64, 64]",
            "[3, 128, 64, 32]",
            "[3, 16, 64, 128, 256, 512]",
            "[3, 6, 16, 32, 64]",
          ]
          value_type: str

# TODO
#  Stride
# Skip Connection
# 8*8 ~
# Deeper CNN with 1X1 conv

