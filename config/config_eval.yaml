defaults:
  - hydra/job_logging: disabled
  - hydra/output_subdir: null

main:
  experiment_name_prefix: my_exp
  seed: 1
  num_workers: 5 #todo increase?
  use_full: True
  start_from_pretrained_model: False # If True make sure not using AX!!! and make sure model actually exists!
  full:
    paths:
      pretrained_model_path: './model.pth'
      base_path: '/datashare'
#      base_path: './zip'
      logs: 'logs/'
      vocab_path: './vocab.json'
    train_paths:
      vqaDataset: './vqaDataset_train.pkl'
      questions: 'v2_OpenEnded_mscoco_train2014_questions.json'
      answers: 'v2_mscoco_train2014_annotations.json'
      imgs: 'train2014'
      processed_imgs: './processed_train_images.h5'
    val_paths:
      vqaDataset: './vqaDataset_val.pkl'
      questions: 'v2_OpenEnded_mscoco_val2014_questions.json'
      answers: 'v2_mscoco_val2014_annotations.json'
      imgs: 'val2014'
      processed_imgs: './processed_val_images.h5'
  small:
    paths:
      pretrained_model_path: './model_small.pth'
      base_path: './small_data'
      logs: 'logs/'
      vocab_path: './vocab_small.json'
    train_paths:
      vqaDataset: './vqaDataset_train_small.pkl'
      questions: 'v2_OpenEnded_mscoco_train2014_questions.json'
      answers: 'v2_mscoco_train2014_annotations.json'
      imgs: 'train2014'
      processed_imgs: './processed_train_images_small.h5'
    val_paths:
      vqaDataset: './vqaDataset_val_small.pkl'
      questions: 'v2_OpenEnded_mscoco_val2014_questions.json'
      answers: 'v2_mscoco_val2014_annotations.json'
      imgs: 'val2014'
      processed_imgs: './processed_val_images_small.h5'
train:
  text:
    question_features: 1024
    embedding_features: 300
    dropout: 0.4
    num_lstm_layers: 1 # TODO change code if True!!
    bidirectional: True # False # OVERRIDEN
  image:
    kernel_size: 3
    dropout: 0.4
    # num_channels OVERRIDEN
    num_channels: [3, 64, 128, 256] # last entry should match image_features
    stride: 2  # OVERRIDEN
    do_skip_connection: False  # OVERRIDEN
  attention:
    hidden_dim: 1024
    glimpses: 2
    do_option: "*" # Options "*" / "+" / "|"  # OVERRIDEN
    dropout: 0.4
  classifier:
    hidden_dim: 1024
    dropout: 0.4

  max_answers: 3000
  image_size: 224 # scale shorter end of image to this size and centre crop
  central_fraction: 0.875  # only take this much of the centre when scaling and centre cropping

  n_epochs_stop: 6
  num_epochs: 2
  batch_size: 64
  save_model: True
  lr: # TODO what are reasonable values?
    lr_value: 1e-3
    lr_decay: 15
    lr_gamma: 0.1
    lr_step_size: 3
hydra:
  output_subdir: null
  run:
    dir: logs/hydra
